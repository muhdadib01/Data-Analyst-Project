# -*- coding: utf-8 -*-
"""Diabetes Prediction Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VLLFjBu0hyr6_ZYEvKYo0dA_4QpnSuEe

1.IMPORT DATASET
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt #to plot charts
import seaborn as sns #used for data visualization
import warnings #avoid warning flash

warnings.filterwarnings('ignore')

df=pd.read_csv("diabetes.csv")

df.head()

df.info()

"""2. DATA PREPROCESSING"""

df=df.drop_duplicates() # drop duplicates

df=df.dropna() # drop null values

print(df[df['BloodPressure']==0].shape[0])
print(df[df['Glucose']==0].shape[0])
print(df[df['SkinThickness']==0].shape[0])
print(df[df['Insulin']==0].shape[0])
print(df[df['BMI']==0].shape[0])

df['Glucose']=df['Glucose'].replace(0,df['Glucose'].mean())#normal distribution
df['BloodPressure']=df['BloodPressure'].replace(0,df['BloodPressure'].mean())#normal distribution
df['SkinThickness']=df['SkinThickness'].replace(0,df['SkinThickness'].median())#skewed distribution
df['Insulin']=df['Insulin'].replace(0,df['Insulin'].median())#skewed distribution
df['BMI']=df['BMI'].replace(0,df['BMI'].median())#skewed distribution

sns.countplot('Outcome',data=df)

df.hist(bins=10,figsize=(10,10))
plt.show()

plt.figure(figsize=(16,12))
sns.set_style(style='whitegrid')
plt.subplot(3,3,1)
sns.boxplot(x='Glucose',data=df)
plt.subplot(3,3,2)
sns.boxplot(x='BloodPressure',data=df)
plt.subplot(3,3,3)
sns.boxplot(x='Insulin',data=df)
plt.subplot(3,3,4)
sns.boxplot(x='BMI',data=df)
plt.subplot(3,3,5)
sns.boxplot(x='Age',data=df)
plt.subplot(3,3,6)
sns.boxplot(x='SkinThickness',data=df)
plt.subplot(3,3,7)
sns.boxplot(x='Pregnancies',data=df)
plt.subplot(3,3,8)
sns.boxplot(x='DiabetesPedigreeFunction',data=df)

from pandas.plotting import scatter_matrix
scatter_matrix(df,figsize=(20,20));
# we can come to various conclusion looking at these plots for example  if you observe 5th plot in pregnancies with insulin, you can conclude that women with higher number of pregnancies have lower insulin

"""3. FEATURE SELECTION"""

#only look outcome
corrmat=df.corr()
sns.heatmap(corrmat, annot=True)

df_selected=df.drop(['BloodPressure','Insulin','DiabetesPedigreeFunction'],axis='columns')
df_selected.head()

"""4. HANDLING OUTLIERS"""

from sklearn.preprocessing import QuantileTransformer
x=df_selected
quantile  = QuantileTransformer()
X = quantile.fit_transform(x)
df_new=quantile.transform(X)
df_new=pd.DataFrame(X)
df_new.columns =['Pregnancies', 'Glucose','SkinThickness','BMI','Age','Outcome']
df_new.head()

plt.figure(figsize=(16,12))
sns.set_style(style='whitegrid')
plt.subplot(3,3,1)
sns.boxplot(x=df_new['Glucose'],data=df_new)
plt.subplot(3,3,2)
sns.boxplot(x=df_new['BMI'],data=df_new)
plt.subplot(3,3,3)
sns.boxplot(x=df_new['Pregnancies'],data=df_new)
plt.subplot(3,3,4)
sns.boxplot(x=df_new['Age'],data=df_new)
plt.subplot(3,3,5)
sns.boxplot(x=df_new['SkinThickness'],data=df_new)

"""5. SPLIT DATA INTO X AND Y"""

target_name='Outcome'
y= df_new[target_name]#given predictions - training data
X=df_new.drop(target_name,axis=1)#dropping the Outcome column and keeping all other columns as X

X.head() # contains only independent features

y.head() #contains dependent feature

"""6. SPLIT TRAIN TEST"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.2,random_state=0)#splitting data in 80% train, 20%test

X_train.shape,y_train.shape

X_test.shape,y_test.shape

"""7. NAIVE BAYES MODEL"""

from sklearn.metrics import classification_report,confusion_matrix
from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score
from sklearn.model_selection import GridSearchCV
from sklearn import metrics

from sklearn.naive_bayes import GaussianNB

param_grid_nb = {
    'var_smoothing': np.logspace(0,-2, num=100)
}
nbModel_grid = GridSearchCV(estimator=GaussianNB(), param_grid=param_grid_nb, verbose=1, cv=10, n_jobs=-1)
best_model= nbModel_grid.fit(X_train, y_train)

nb_pred=best_model.predict(X_test)

print("Classification Report is:\n",classification_report(y_test,nb_pred))

print("\n Accuracy score is:\n",accuracy_score(y_test,nb_pred))
print("\n F1:\n",f1_score(y_test,nb_pred))
print("\n Precision score is:\n",precision_score(y_test,nb_pred))
print("\n Recall score is:\n",recall_score(y_test,nb_pred))

print("\n Confusion Matrix:\n")
sns.heatmap(confusion_matrix(y_test,nb_pred),annot=True, fmt='g')
sns.set(font_scale=1.5)
plt.xlabel("Predicted")
plt.ylabel("Actual")

"""8. SUPPORT VECTOR MACHINE MODEL"""

from sklearn.svm import SVC
from sklearn.model_selection import RepeatedStratifiedKFold

model = SVC()
kernel = ['poly', 'rbf', 'sigmoid']
C = [50, 10, 1.0, 0.1, 0.01]
gamma = ['scale']

grid = dict(kernel=kernel,C=C,gamma=gamma)
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search2 = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='f1',error_score=0)

grid_result = grid_search2.fit(X, y)

svm_pred=grid_result.predict(X_test)

print("Classification Report is:\n",classification_report(y_test,svm_pred))

print("\n Accuracy score is:\n",accuracy_score(y_test,svm_pred))
print("\n F1:\n",f1_score(y_test,svm_pred))
print("\n Precision score is:\n",precision_score(y_test,svm_pred))
print("\n Recall score is:\n",recall_score(y_test,svm_pred))

print("\n Confusion Matrix:\n")
sns.heatmap(confusion_matrix(y_test,svm_pred),annot=True, fmt='g')
sns.set(font_scale=1.5)
plt.xlabel("Predicted")
plt.ylabel("Actual")

"""9. DECISION TREE MODEL"""

from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier(random_state=42)

params = {
    'max_depth': [5, 10, 20,25],
    'min_samples_leaf': [10, 20, 50, 100,120],
    'criterion': ["gini", "entropy"]
}

grid_search = GridSearchCV(estimator=dt,
                           param_grid=params,
                           cv=4, n_jobs=-1, verbose=1, scoring = "accuracy")

best_model=grid_search.fit(X_train, y_train)

dt_pred=best_model.predict(X_test)

print("Classification Report is:\n",classification_report(y_test,dt_pred))

print("\n Accuracy score is:\n",accuracy_score(y_test,dt_pred))
print("\n F1:\n",f1_score(y_test,dt_pred))
print("\n Precision score is:\n",precision_score(y_test,dt_pred))
print("\n Recall score is:\n",recall_score(y_test,dt_pred))

print("\n Confusion Matrix:\n")
sns.heatmap(confusion_matrix(y_test,dt_pred),annot=True, fmt='g')
sns.set(font_scale=1.5)
plt.xlabel("Predicted")
plt.ylabel("Actual")

"""10. ROC CURVE"""

# IMPORTANT: first argument is true values, second argument is predicted probabilities

# we pass y_test and y_pred_prob
# we do not use y_pred_class, because it will give incorrect results without generating an error
# roc_curve returns 3 objects false positive rate(fpr), true positive rate(tpr), thresholds
from sklearn import metrics

fpr_nb, tpr_nb, thresholds_nb = metrics.roc_curve(y_test, nb_pred)
fpr_svm, tpr_svm, thresholds_svm = metrics.roc_curve(y_test, svm_pred)
fpr_dt, tpr_dt, thresholds_dt = metrics.roc_curve(y_test, dt_pred)

#area under roc curve
plt.fill_between(fpr_nb, tpr_nb, facecolor='lightblue', alpha=0.7)

plt.plot(fpr_nb, tpr_nb, label="nb")
plt.plot(fpr_svm, tpr_svm, label="svm")
plt.plot(fpr_dt, tpr_dt, label="dt")
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.rcParams['font.size'] = 10
plt.title('ROC curve')
plt.xlabel('False Positive Rate (1 - Specificity)')
plt.ylabel('True Positive Rate (Sensitivity)')
plt.legend(loc="lower right", fontsize=15)
plt.grid(True)
sns.set(font_scale=1)
plt.plot([0,1],[0,1],'k--')

"""11. AUC"""

#Area under ROC curve = AUC
from sklearn.metrics import roc_auc_score
roc_score_nb = roc_auc_score(y_test, nb_pred)
roc_score_svm = roc_auc_score(y_test, svm_pred)
roc_score_dt = roc_auc_score(y_test, dt_pred)
print("\n Naive Bayes :\n",roc_score_nb)
print("\n Support Vector Machine:\n",roc_score_svm)
print("\n Decision Tree:\n",roc_score_dt)

plt.title('AUC')
plt.bar(['NB','SVM','DT'],[roc_score_nb,roc_score_svm,roc_score_dt])
plt.xlabel("Algorithms")
plt.ylabel("Accuracy")
plt.show()

"""12. PREDICTION ACCURACY GRAPH"""

plt.title('Prediction Model Accuracy')
plt.bar(['NB','SVM','DT'],[accuracy_score(y_test,nb_pred),accuracy_score(y_test,svm_pred),accuracy_score(y_test,dt_pred)])
plt.xlabel("Algorithms")
plt.ylabel("Accuracy")
plt.show()

"""13. PREDICTION MODEL COMPARISON TABLE"""

import pandas as pd

# Create a dataframe
data = {'algorithm': ['NB', 'SVM', 'DT'],
         'accuracy': [accuracy_score(y_test,nb_pred),accuracy_score(y_test,svm_pred),accuracy_score(y_test,dt_pred)],
           'recall': [recall_score(y_test,nb_pred),recall_score(y_test,svm_pred),recall_score(y_test,dt_pred)],
        'precision': [precision_score(y_test,nb_pred),precision_score(y_test,svm_pred),precision_score(y_test,dt_pred)],
         'f1-score': [f1_score(y_test,nb_pred),f1_score(y_test,svm_pred),f1_score(y_test,dt_pred)],
              'AUC': [roc_score_nb,roc_score_svm,roc_score_dt],
       }
table = pd.DataFrame(data)

# Print the table
print(table)

"""14. PREDICTION TEST"""

def predict_diabetes(attributes):
    prediction = nbModel_grid.predict([attributes])[0]
    if prediction == 1:
        return "Yes"
    else:
        return "No"

def predict_diabetes(attributes):
    prediction2 = grid_search2.predict([attributes])[0]
    if prediction2 == 1:
        return "Yes"
    else:
        return "No"

def predict_diabetes(attributes):
    prediction3 = grid_search.predict([attributes])[0]
    if prediction3 == 1:
        return "Yes"
    else:
        return "No"

# test the prediction function with sample data
sample_data = [0.747718,0.810300,0.801825,0.591265,0.889831]
prediction = predict_diabetes(sample_data)
print("Prediction Naive Bayes:", prediction)
prediction2 = predict_diabetes(sample_data)
print("Prediction Support Vector Machine:", prediction2)
prediction3 = predict_diabetes(sample_data)
print("Prediction Decision Tree:", prediction3)